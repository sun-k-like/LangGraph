"""
Adaptive RAG with LangGraph
- ì‹œê°„ì„± ê°ì§€ë¡œ ì›¹ê²€ìƒ‰ vs ì¸ë±ìŠ¤ ìë™ì„ íƒ
- Self-corrective ë£¨í”„ë¥¼ í†µí•œ í’ˆì§ˆ ê²€ì¦
"""

from typing import TypedDict, List
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langgraph.graph import StateGraph, END
from dotenv import load_dotenv
import os

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ========== 1. State ì •ì˜ (RAGìš©) ==========
class GraphState(TypedDict):
    """RAG ì›Œí¬í”Œë¡œìš°ì˜ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” ë”•ì…”ë„ˆë¦¬"""
    query: str              # ì‚¬ìš©ì ì§ˆë¬¸
    documents: List[str]    # ê²€ìƒ‰ëœ ë¬¸ì„œ ìŠ¤ë‹ˆí«
    answer: str            # ìƒì„±ëœ ë‹µë³€
    sources: List[str]     # ì¶œì²˜ ëª©ë¡
    search_type: str       # ê²€ìƒ‰ ì „ëµ (web/index)
    needs_correction: bool # ì¬ì§ˆì˜ í•„ìš” ì—¬ë¶€


# ========== 2. ì„ë² ë”© ëª¨ë¸ ë° ë²¡í„° DB ì„¤ì • ==========
# Azure OpenAI Embeddings
embeddings = AzureOpenAIEmbeddings(
    azure_deployment=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT", "text-embedding-3-small"),
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY")
)

# Azure OpenAI LLM (Chat Model)
llm = AzureChatOpenAI(
    azure_deployment=os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT", "gpt-4.1"),
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    temperature=0
)

# ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” (Chroma DB)
vectorstore = None  # ë¬¸ì„œ ë¡œë“œ í›„ ì´ˆê¸°í™”


def setup_vectorstore(pdf_path: str):
    """PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±"""
    global vectorstore
    
    # PDF ë¡œë“œ
    loader = PyPDFLoader(pdf_path)
    docs = loader.load()
    
    # í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    splits = text_splitter.split_documents(docs)
    
    # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory="./chroma_db"
    )
    
    print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {len(splits)}ê°œ ì²­í¬")


# ========== 3. ì¿¼ë¦¬ ë¶„ì„ ë…¸ë“œ ==========
def analyze_query(state: GraphState) -> GraphState:
    """
    ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì „ëµ ê²°ì •
    - ì‹œê°„ì„± í‚¤ì›Œë“œ ê°ì§€ â†’ ì›¹ê²€ìƒ‰
    - ì¼ë°˜ ì§ˆë¬¸ â†’ ì¸ë±ìŠ¤ ê²€ìƒ‰
    """
    query = state["query"]
    
    # ì‹œê°„ì„± í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    time_keywords = ["ìµœì‹ ", "í˜„ì¬", "ì˜¤ëŠ˜", "ì§€ê¸ˆ", "today", "recent", "latest", "2024", "2025"]
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
    if any(keyword in query.lower() for keyword in time_keywords):
        search_type = "web"
        print(f"ğŸŒ ì›¹ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ (ì‹œê°„ì„± ê°ì§€)")
    else:
        search_type = "index"
        print(f"ğŸ“š ì¸ë±ìŠ¤ ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ")
    
    state["search_type"] = search_type
    return state


# ========== 4. ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ ==========
def retrieve_documents(state: GraphState) -> GraphState:
    """
    ê²€ìƒ‰ ì „ëµì— ë”°ë¼ ë¬¸ì„œ ê²€ìƒ‰
    - web: Azure OpenAIë¡œ ì›¹ê²€ìƒ‰ ì§ˆì˜
    - index: ë²¡í„°DB ê²€ìƒ‰
    """
    query = state["query"]
    search_type = state["search_type"]
    
    if search_type == "index":
        # ë²¡í„°DBì—ì„œ ê²€ìƒ‰
        if vectorstore is None:
            state["documents"] = []
            state["sources"] = []
            print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return state
        
        retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3}  # ìƒìœ„ 3ê°œ ë¬¸ì„œ
        )
        docs = retriever.invoke(query)
        
        state["documents"] = [doc.page_content for doc in docs]
        state["sources"] = [f"Page {doc.metadata.get('page', 'N/A')}" for doc in docs]
        print(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(docs)}ê°œ")
        
    else:  # web
        # Azure OpenAIë¡œ ì›¹ ì •ë³´ ê²€ìƒ‰
        try:
            # ì›¹ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸
            web_search_prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
ì¸í„°ë„·ì—ì„œ ê²€ìƒ‰í•œ ê²ƒì²˜ëŸ¼ ìµœì‹  ì •ë³´ì™€ ì¶œì²˜ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

ë‹µë³€ í˜•ì‹:
1. í•µì‹¬ ì •ë³´ (3-5ë¬¸ì¥)
2. ì¶”ê°€ ì„¸ë¶€ì‚¬í•­
3. ì¶œì²˜ ì •ë³´"""

            response = llm.invoke(web_search_prompt)
            content = response.content
            
            # ì‘ë‹µì„ ë¬¸ì„œì™€ ì¶œì²˜ë¡œ ë¶„ë¦¬
            state["documents"] = [content]
            state["sources"] = ["Azure OpenAI (Web Knowledge)"]
            print(f"ğŸŒ ì›¹ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ ì›¹ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            state["documents"] = [f"ì›¹ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"]
            state["sources"] = ["Error"]
    
    return state


# ========== 5. ì‘ë‹µ ìƒì„± ë…¸ë“œ ==========
def generate_answer(state: GraphState) -> GraphState:
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±
    """
    query = state["query"]
    documents = state["documents"]
    
    if not documents:
        state["answer"] = "ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ì–´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        state["needs_correction"] = True
        return state
    
    # Azure LLM ì‚¬ìš© (ì „ì—­ ë³€ìˆ˜)
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    context = "\n\n".join(documents)
    prompt = f"""ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""
    
    # ë‹µë³€ ìƒì„±
    response = llm.invoke(prompt)
    state["answer"] = response.content
    state["needs_correction"] = False
    
    print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
    return state


# ========== 6. í’ˆì§ˆ ê²€ì¦ ë…¸ë“œ ==========
def verify_quality(state: GraphState) -> GraphState:
    """
    ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆ ê²€ì¦
    - ê·¼ê±° ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
    """
    answer = state["answer"]
    documents = state["documents"]
    
    # ê°„ë‹¨í•œ ê²€ì¦: ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš°
    if len(answer) < 20 or not documents:
        state["needs_correction"] = True
        print(f"âš ï¸ í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ - ì¬ì§ˆì˜ í•„ìš”")
    else:
        state["needs_correction"] = False
        print(f"âœ… í’ˆì§ˆ ê²€ì¦ í†µê³¼")
    
    return state


# ========== 7. ë¼ìš°íŒ… í•¨ìˆ˜ ==========
def should_correct(state: GraphState) -> str:
    """
    ì¬ì§ˆì˜ í•„ìš” ì—¬ë¶€ì— ë”°ë¼ ë¼ìš°íŒ…
    """
    if state["needs_correction"]:
        return "correct"
    else:
        return "end"


# ========== 8. ê·¸ë˜í”„ êµ¬ì„± ==========
def build_graph():
    """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
    workflow = StateGraph(GraphState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("analyze", analyze_query)
    workflow.add_node("retrieve", retrieve_documents)
    workflow.add_node("generate", generate_answer)
    workflow.add_node("verify", verify_quality)
    
    # ì—£ì§€ ì—°ê²°
    workflow.set_entry_point("analyze")
    workflow.add_edge("analyze", "retrieve")
    workflow.add_edge("retrieve", "generate")
    workflow.add_edge("generate", "verify")
    
    # ì¡°ê±´ë¶€ ì—£ì§€ (Self-corrective ë£¨í”„)
    workflow.add_conditional_edges(
        "verify",
        should_correct,
        {
            "correct": "retrieve",  # ì¬ê²€ìƒ‰
            "end": END
        }
    )
    
    return workflow.compile()


# ========== 9. ì‹¤í–‰ í•¨ìˆ˜ ==========
def run_rag(query: str):
    """RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    graph = build_graph()
    
    # ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "query": query,
        "documents": [],
        "answer": "",
        "sources": [],
        "search_type": "",
        "needs_correction": False
    }
    
    # ê·¸ë˜í”„ ì‹¤í–‰
    print(f"\n{'='*60}")
    print(f"ğŸ” ì¿¼ë¦¬: {query}")
    print(f"{'='*60}\n")
    
    result = graph.invoke(initial_state)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ“ ìµœì¢… ë‹µë³€:")
    print(f"{result['answer']}")
    print(f"\nğŸ“š ì¶œì²˜: {', '.join(result['sources'])}")
    print(f"{'='*60}\n")
    
    return result


# ========== 10. ë©”ì¸ ì‹¤í–‰ ==========
if __name__ == "__main__":
    # Azure OpenAI API ì„¤ì • í™•ì¸ (ìµœì†Œ í•„ìˆ˜ í•­ëª©ë§Œ)
    required_env_vars = [
        "AZURE_OPENAI_ENDPOINT",
        "AZURE_OPENAI_API_KEY"
    ]
    
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        print("âš ï¸ ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:")
        for var in missing_vars:
            print(f"   - {var}")
        print("\nğŸ’¡ .env íŒŒì¼ì— ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”:")
        print("AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/")
        print("AZURE_OPENAI_API_KEY=your-api-key")
        print("\nğŸ“Œ ì„ íƒì‚¬í•­ (ê¸°ë³¸ê°’ì´ ìˆì–´ì„œ ìƒëµ ê°€ëŠ¥):")
        print("AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4.1  # ê¸°ë³¸ê°’: gpt-4.1")
        print("AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small  # ê¸°ë³¸ê°’: text-embedding-3-small")
        print("AZURE_OPENAI_API_VERSION=2024-02-01  # ê¸°ë³¸ê°’: 2024-02-01")
        exit(1)
    
    # Endpoint ë§ˆìŠ¤í‚¹ ì²˜ë¦¬
    endpoint = os.getenv('AZURE_OPENAI_ENDPOINT', '')
    if len(endpoint) > 16:
        masked_endpoint = endpoint[:8] + "********" + endpoint[16:]
    else:
        masked_endpoint = "***"
    
    print("âœ… Azure OpenAI ì„¤ì • í™•ì¸ ì™„ë£Œ")
    print(f"   Endpoint: {masked_endpoint}")
    print(f"   Chat Deployment: {os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT', 'gpt-4.1 (ê¸°ë³¸ê°’)')}")
    print(f"   Embedding Deployment: {os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT', 'text-embedding-3-small (ê¸°ë³¸ê°’)')}")
    
    # 1ë‹¨ê³„: PDF ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ì„ íƒ)
    print("\n" + "="*60)
    print("ğŸ“š ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •")
    print("="*60)
    
    # PDF íŒŒì¼ ê²½ë¡œ ì§€ì • (ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)
    pdf_path = "docs/manual.pdf"  # ğŸ‘ˆ ì—¬ê¸°ë¥¼ ì‹¤ì œ PDF ê²½ë¡œë¡œ ë³€ê²½
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if os.path.exists(pdf_path):
        setup_vectorstore(pdf_path)
    else:
        print(f"â„¹ï¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        print("   ì›¹ê²€ìƒ‰ ëª¨ë“œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    # 2ë‹¨ê³„: RAG ì‹¤í–‰
    print("\n" + "="*60)
    print("ğŸ¤– RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # ì˜ˆì‹œ ì¿¼ë¦¬ ì‹¤í–‰
    if vectorstore:
        print("\n[í…ŒìŠ¤íŠ¸ 1] ì¸ë±ìŠ¤ ê²€ìƒ‰ ëª¨ë“œ")
        run_rag("ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?")
    
    print("\n[í…ŒìŠ¤íŠ¸ 2] ì›¹ê²€ìƒ‰ ëª¨ë“œ")
    run_rag("ìµœì‹  AI ê¸°ìˆ  ë™í–¥ì€?")  # ì‹œê°„ì„± í‚¤ì›Œë“œë¡œ ì›¹ê²€ìƒ‰ íŠ¸ë¦¬ê±°